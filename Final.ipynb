{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pitch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8VXSOOBELdZ",
        "outputId": "30c1bac3-ede4-4f56-eff4-e7100fbee4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pitch\n",
            "  Downloading pitch-0.0.6-py3-none-any.whl (2.6 kB)\n",
            "Installing collected packages: pitch\n",
            "Successfully installed pitch-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install packages\n",
        "!pip install librosa\n",
        "!pip install wave\n",
        "!pip install scipy\n",
        "!pip install pydub\n",
        "!pip install  soundfile\n",
        "!pip install pygobject\n",
        "!pip install Audio"
      ],
      "metadata": {
        "id": "9exrTgfqmjj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyloudnorm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NezUcqAEeDU3",
        "outputId": "c31fb19e-2344-40d4-cb2f-06871d86db34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyloudnorm\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.23.5)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (0.18.3)\n",
            "Installing collected packages: pyloudnorm\n",
            "Successfully installed pyloudnorm-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import wave\n",
        "import scipy\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from pydub.utils import db_to_float\n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.silence import detect_silence"
      ],
      "metadata": {
        "id": "3N56J0ireOZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pitch\n",
        "import pyloudnorm as pyln\n",
        "\n",
        "# Function to compute RMSE\n",
        "def rmse(x):\n",
        "    return np.sum(x**2)\n",
        "    pass\n",
        "\n",
        "folder_path = '/content/temp_data'\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Create a CSV file to write the features\n",
        "csv_file_path = '/content/features.csv'\n",
        "\n",
        "# Open the CSV file in write mode\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    # Create a CSV writer object\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "\n",
        " # Write the header row with feature names\n",
        "    header = ['File', 'Pitch', 'RMSE'] + [f'LPC_{i}' for i in range(1, 14)] + [f'MFCC_{i}' for i in range(1, 14)] + ['Intensity','Shimmer', 'Jitter', 'Emotion']\n",
        "    csv_writer.writerow(header)\n",
        "\n",
        "    # Iterate over each file\n",
        "    for file in files:\n",
        "        # Construct the full path to the file\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        part=file.split('_')\n",
        "        if part[2] == 'SAD':\n",
        "            file_emotion = 'sad'\n",
        "        elif part[2] == 'ANG':\n",
        "            file_emotion = 'angry'\n",
        "        elif part[2] == 'DIS':\n",
        "            file_emotion = 'disgust'\n",
        "        elif part[2]== 'FEA':\n",
        "            file_emotion = 'fear'\n",
        "        elif part[2] == 'HAP':\n",
        "            file_emotion = 'happy'\n",
        "        elif part[2] == 'NEU':\n",
        "            file_emotion = 'neutral'\n",
        "        else:\n",
        "            file_emotion = 'Unknown'\n",
        "\n",
        "\n",
        "\n",
        "        # Load audio file\n",
        "        x, sr = librosa.load(file_path)\n",
        "\n",
        "        # Find pitch\n",
        "        p = pitch.find_pitch(file_path)\n",
        "\n",
        "        # Compute RMSE\n",
        "        rmse_value = rmse(x)\n",
        "\n",
        "        # Compute LPC\n",
        "        lpc = librosa.lpc(x, order=12)\n",
        "\n",
        "        # Compute MFCCs\n",
        "        mfccs = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13).mean(axis=1)\n",
        "\n",
        "        data, rate = sf.read(file_path)\n",
        "        meter = pyln.Meter(rate)\n",
        "        loudness = meter.integrated_loudness(data)\n",
        "        positive_intensity = abs(loudness)\n",
        "\n",
        "        sums=0\n",
        "\n",
        "        peak=scipy.signal.find_peaks(x,rel_height=0.5)\n",
        "\n",
        "        #JITTER, SHIMMER, JITTERRAP\n",
        "        for i in range(1,len(peak[0])-1):\n",
        "          sums=sums+abs(20*math.log10(peak[0][i+1]/peak[0][i]))\n",
        "\n",
        "        #SHIMMER\n",
        "        shimmer=sums/(len(peak[0])-1)\n",
        "        peakf=abs(np.fft.fft(peak[0]))\n",
        "        sumps=0\n",
        "        for i in range(1,len(peakf)-1):\n",
        "          sumps=sumps+(peakf[i+1]**-1)-(peakf[i]**-1)\n",
        "\n",
        "\n",
        "        #JITTER\n",
        "        jitter=sumps/(len(peakf)-1)\n",
        "        sortedp=np.sort(peak[0])\n",
        "        sortedf=abs(np.fft.fft(sortedp))\n",
        "        dif=abs(sortedp[11]-sortedp[15])\n",
        "        suh=0\n",
        "        avgabsdiff=(dif)/4\n",
        "        avgneigh1=(abs(sortedp[6]-sortedp[10]))\n",
        "        avgneigh2=abs(sortedp[17]-sortedp[22])\n",
        "        avg=(dif+avgneigh1+avgneigh2)/3\n",
        "\n",
        "        for i in range(11,16):\n",
        "          suh=suh+abs(sortedf[i]**-1)\n",
        "        period=suh/5\n",
        "\n",
        "\n",
        "\n",
        "        # Write the row to the CSV file\n",
        "        row = [file, p, rmse_value] + list(lpc) + list(mfccs) + [positive_intensity,shimmer, jitter, file_emotion]\n",
        "        csv_writer.writerow(row)\n",
        "\n",
        "# Print a message indicating the completion\n",
        "print(f'Features have been written to {csv_file_path}')\n",
        "\n"
      ],
      "metadata": {
        "id": "u2wfx-NQwEmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkmiTgexFGIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "confusion_matrices = []\n",
        "\n",
        "file_path = '/content/final_features_(1).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Preprocess data if needed\n",
        "\n",
        "# Step 3: Convert string labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "data['Emotion'] = label_encoder.fit_transform(data['Emotion'])\n",
        "\n",
        "# Step 4: Split into features and labels\n",
        "X = data.drop(['File','Emotion'], axis=1)\n",
        "y = data['Emotion']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "rf_scores = cross_val_score(rf_model, X_standardized, y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "# Print the accuracy for each fold\n",
        "for i, score in enumerate(rf_scores, 1):\n",
        "    print(f'RF Fold {i}: Accuracy = {score:.4f}')\n",
        "\n",
        "# Print the average accuracy across all folds\n",
        "print(f'RF Average Accuracy: {rf_scores.mean():.4f}')\n"
      ],
      "metadata": {
        "id": "_vzuUhCG-fey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "Gq2F3N5cEsIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
        "\n",
        "def train_model(file_path):\n",
        "    # Load CSV file\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Preprocess data if needed\n",
        "\n",
        "    # Convert string labels to numeric values\n",
        "    label_encoder = LabelEncoder()\n",
        "    data['Emotion'] = label_encoder.fit_transform(data['Emotion'])\n",
        "\n",
        "    # Split into features and labels\n",
        "    X = data.drop(['File', 'Emotion'], axis=1)\n",
        "    y = data['Emotion']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "    # Create an SVM model\n",
        "    svm_model = SVC()\n",
        "\n",
        "    # Perform K-fold cross-validation\n",
        "    num_folds = 5\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # Define variables outside the loop\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kfold.split(X_standardized)):\n",
        "        # Split the data into training and testing sets for this fold\n",
        "        X_train, X_test = X_standardized[train_index], X_standardized[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Train the model on the training set\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the testing set\n",
        "        y_pred = svm_model.predict(X_test)\n",
        "\n",
        "        # Append true and predicted labels for computing overall metrics\n",
        "        y_true_all.extend(y_test)\n",
        "        y_pred_all.extend(y_pred)\n",
        "\n",
        "        # Compute evaluation metrics for this fold\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "        # Print the evaluation metrics for each fold\n",
        "        print(f'\\nFold {i + 1} Metrics for {file_path}:')\n",
        "        print(f'Precision = {precision:.4f}')\n",
        "        print(f'Recall = {recall:.4f}')\n",
        "        print(f'F1 Score = {f1:.4f}')\n",
        "        print(f'Confusion Matrix:\\n{confusion_mat}')\n",
        "\n",
        "    # Compute overall metrics using all folds\n",
        "    overall_precision = precision_score(y_true_all, y_pred_all, average='weighted')\n",
        "    overall_recall = recall_score(y_true_all, y_pred_all, average='weighted')\n",
        "    overall_f1 = f1_score(y_true_all, y_pred_all, average='weighted')\n",
        "    overall_confusion_mat = confusion_matrix(y_true_all, y_pred_all)\n",
        "    overall_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
        "\n",
        "    # Print overall metrics\n",
        "    print(f'\\nOverall Metrics for {file_path}:')\n",
        "    print(f'Overall Precision = {overall_precision:.4f}')\n",
        "    print(f'Overall Recall = {overall_recall:.4f}')\n",
        "    print(f'Overall F1 Score = {overall_f1:.4f}')\n",
        "    print(f'Overall Accuracy = {overall_accuracy:.4f}')\n",
        "    print(f'Overall Confusion Matrix:\\n{overall_confusion_mat}')\n",
        "\n",
        "# Train the model with the first CSV file\n",
        "file_path_1 = '/content/features.csv'\n",
        "train_model(file_path_1)\n",
        "\n",
        "#Train the model with the second CSV file\n",
        "file_path_2 = '/content/final_features_(1).csv'\n",
        "train_model(file_path_2)\n",
        "\n",
        "#Train the model with the second CSV file\n",
        "file_path_3 = '/content/final_features_1.csv'\n",
        "train_model(file_path_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsYeGlXkqJFx",
        "outputId": "3e200d3a-e412-4f5c-afe5-66599c014a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1 Metrics for /content/features.csv:\n",
            "Precision = 0.3713\n",
            "Recall = 0.4276\n",
            "F1 Score = 0.3922\n",
            "Confusion Matrix:\n",
            "[[  8   0   0  10   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [  0   3   2   1   0   0   1   0   0   0   0   0   0   0   0   2   7   0\n",
            "    0   0   0]\n",
            " [  0   1   0   7   0   0   1   0   1   0   0   0   0   0   0   2   3   0\n",
            "    0   0   0]\n",
            " [  2   0   0 110   0   0   0   3   1   0   0   9   0   0   0  20   4   0\n",
            "    0   0   2]\n",
            " [  0   0   0   4   0   1   0   1   0   0   0   4   0   0   0   1   3   0\n",
            "    0   0   2]\n",
            " [  0   1   0   0   0   1   0   1   0   0   0   0   0   0   0   0   2   0\n",
            "    2   0   3]\n",
            " [  0   2   0   3   1   1   0   2   0   0   0   1   0   0   0   0   1   0\n",
            "    0   0   2]\n",
            " [  0   0   0  11   0   1   0  46   0   0   0  11   0   0   0  12  22   0\n",
            "    0   0  31]\n",
            " [  1   0   0   2   0   0   0   0   1   0   0   2   0   0   0   2   1   0\n",
            "    0   0   0]\n",
            " [  0   0   0   0   0   1   0   1   0   0   0   3   0   0   0   0   2   0\n",
            "    0   0   3]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   1   0   0   0   3   3   0\n",
            "    1   0   8]\n",
            " [  0   1   0  14   0   0   1  12   1   0   0  35   0   0   0  21  17   0\n",
            "    0   0  19]\n",
            " [  2   1   0   3   0   0   0   0   1   0   0   0   0   0   0   2   2   0\n",
            "    0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   9   0\n",
            "    0   0   0]\n",
            " [  0   0   0   1   0   0   0   2   0   0   0   2   0   0   0   5   4   0\n",
            "    0   0   0]\n",
            " [  0   0   0  29   0   0   0  17   0   0   0  19   0   0   0  61  23   0\n",
            "    0   0   1]\n",
            " [  0   0   0   0   0   0   0  24   0   0   0  17   0   0   0  19  90   0\n",
            "    0   0  17]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   1   0   0   0   0   3   0\n",
            "    0   0   5]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1   0\n",
            "    4   0  10]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "    0   0  10]\n",
            " [  0   0   0   0   0   1   0  12   0   0   0   8   0   0   0   3  25   0\n",
            "    0   0  99]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 2 Metrics for /content/features.csv:\n",
            "Precision = 0.3806\n",
            "Recall = 0.4202\n",
            "F1 Score = 0.3853\n",
            "Confusion Matrix:\n",
            "[[  6   0   1   7   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0]\n",
            " [  0   1   0   1   0   0   0   0   1   0   0   0   0   0   0   1   2   0\n",
            "    0   0   0]\n",
            " [  0   0   0   5   0   0   0   0   0   0   0   2   0   0   0   4   0   0\n",
            "    0   0   0]\n",
            " [  2   0   1 108   0   0   0  15   1   0   0   1   0   0   0  27   2   0\n",
            "    0   0   1]\n",
            " [  1   0   0   0   1   0   1   1   0   0   0   0   0   0   0   3   2   0\n",
            "    0   0   0]\n",
            " [  0   0   0   0   0   1   0   2   0   0   0   0   0   0   0   0   5   0\n",
            "    0   0   5]\n",
            " [  0   1   0   0   0   0   0   2   0   0   0   2   0   0   0   5   2   0\n",
            "    0   0   1]\n",
            " [  0   0   0  16   0   0   0  58   0   0   0   6   0   0   0  10  21   0\n",
            "    0   0  22]\n",
            " [  0   0   0   4   0   0   0   0   2   0   0   3   0   0   0   1   1   0\n",
            "    0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0   0   8]\n",
            " [  0   1   0   1   0   0   0   0   0   0   0   3   0   0   0   1   1   0\n",
            "    0   0   5]\n",
            " [  0   0   1  17   0   0   0   8   2   0   0  38   0   0   0  20  32   0\n",
            "    0   0  30]\n",
            " [  0   1   0   3   0   0   1   1   0   0   0   2   0   0   0   3   0   0\n",
            "    0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   9   0\n",
            "    0   0   2]\n",
            " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   6   6   0\n",
            "    0   0   0]\n",
            " [  0   0   0  22   0   0   0  20   0   0   0  10   0   0   0  53  22   0\n",
            "    0   0   7]\n",
            " [  0   0   0   3   0   0   0  22   0   0   0   9   0   0   0  12  90   0\n",
            "    0   0  19]\n",
            " [  0   0   0   0   0   0   0   2   0   0   0   2   0   0   0   0   2   0\n",
            "    0   0   7]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    1   0   9]\n",
            " [  0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0\n",
            "    1   0  16]\n",
            " [  0   0   0   2   0   0   0  20   0   0   0  12   0   0   0   2  31   0\n",
            "    0   0  91]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 3 Metrics for /content/features.csv:\n",
            "Precision = 0.3453\n",
            "Recall = 0.3894\n",
            "F1 Score = 0.3508\n",
            "Confusion Matrix:\n",
            "[[ 4  0  1  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  3  0  0  0  0  0  0  0  1  0  0  0  3  1  0  0  0  0]\n",
            " [ 1  1  0  3  0  0  0  0  0  0  0  1  1  0  0  3  1  0  0  0  0]\n",
            " [ 1  0  0 97  0  0  0  4  0  0  0  2  0  0  0 21  4  0  0  0  0]\n",
            " [ 1  0  0  4  1  0  0  3  0  0  0  2  0  0  0  2  2  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  1  0  6]\n",
            " [ 0  2  0  1  1  0  0  3  0  0  0  3  1  0  0  1  6  0  0  0  0]\n",
            " [ 0  0  0 17  0  1  0 54  0  0  0  8  0  0  0 15 40  0  0  0 27]\n",
            " [ 1  0  0  5  0  0  0  0  0  0  0  4  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  1  0  0  0  2  0  0  0  0  5  0  0  0  5]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  0  3  0  0  0  0  2  0  0  0  8]\n",
            " [ 0  1  0 24  0  0  0 10  0  0  0 40  0  0  0 22 27  0  0  0 33]\n",
            " [ 0  0  0  5  0  0  0  0  0  0  0  2  1  0  0  3  4  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  1  3  0  0  0  3]\n",
            " [ 0  0  0  0  0  0  0  2  0  0  0  1  0  0  0  3  6  0  0  0  0]\n",
            " [ 0  0  0 22  0  0  0 10  0  0  0 12  0  0  0 66 19  0  0  0  5]\n",
            " [ 0  1  0  3  0  0  0 23  0  0  0  8  0  0  0 16 74  0  0  0 26]\n",
            " [ 0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  1  0  0  0  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 15]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  9]\n",
            " [ 0  0  0  1  0  0  0 14  0  0  0  9  0  0  0  4 40  0  0  0 80]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 4 Metrics for /content/features.csv:\n",
            "Precision = 0.3460\n",
            "Recall = 0.4009\n",
            "F1 Score = 0.3611\n",
            "Confusion Matrix:\n",
            "[[ 7  0  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  5  0  0  2  0  0  0  0  3  0  0  0  1  4  0  0  0  0]\n",
            " [ 0  1  0  6  0  0  0  1  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  0 90  0  0  0  7  0  0  0 10  0  0  0 36  3  0  0  0  1]\n",
            " [ 0  0  0  1  0  0  0  2  0  0  0  1  0  0  0  3  1  0  0  0  3]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  6  0  0  0  4]\n",
            " [ 0  1  0  3  1  0  0  0  0  0  0  0  0  0  0  3  3  0  0  0  1]\n",
            " [ 0  0  0 10  0  0  0 55  0  0  0 12  0  0  0 10 35  0  0  0 28]\n",
            " [ 3  0  1  6  0  0  0  0  0  0  0  5  0  0  0  4  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  7  0  0  0  8]\n",
            " [ 0  0  1  1  0  0  0  1  0  0  0  0  0  0  0  1  5  0  0  0  3]\n",
            " [ 0  0  0 16  0  0  0 13  0  0  0 39  0  0  0 29 23  0  0  0 38]\n",
            " [ 0  0  0  6  0  0  0  0  1  0  0  1  0  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  2  1  0  0  1 10  0  0  0  1]\n",
            " [ 0  0  0  1  0  0  0  2  0  0  0  2  0  0  0  0  5  0  0  0  2]\n",
            " [ 0  1  0 25  0  0  0 13  0  0  0 11  0  0  0 66 26  0  0  0  4]\n",
            " [ 0  0  0  0  0  0  0 19  0  0  0  9  0  0  0 11 86  0  0  0 20]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  3  0  0  0 12]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  8]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  7]\n",
            " [ 0  0  0  0  0  0  0 11  0  0  0 10  0  0  0  6 22  0  0  0 84]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 5 Metrics for /content/features.csv:\n",
            "Precision = 0.3267\n",
            "Recall = 0.3804\n",
            "F1 Score = 0.3356\n",
            "Confusion Matrix:\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
            " [ 0  2  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  3  0  0  3  1  0  0  0  0  0  0  0  5  7  0  0  0  0]\n",
            " [ 0  0  0  1 11  0  0  1  0  0  0  0  1  0  0  0  2  2  0  0  0  1]\n",
            " [ 0  1  0  0 90  0  0  0  7  0  0  0  7  0  0  0 22  5  0  0  0  0]\n",
            " [ 0  0  0  0  2  0  0  2  3  0  0  0  2  1  0  0  2  0  0  0  0  2]\n",
            " [ 0  0  0  0  0  0  1  1  2  0  0  0  3  0  0  0  0  2  0  0  0  9]\n",
            " [ 0  0  0  0  1  0  0  0  2  0  0  0  0  0  0  0  1  4  0  0  0  2]\n",
            " [ 0  0  0  0 16  0  0  0 56  0  0  0  3  0  0  0 15 24  0  0  0 24]\n",
            " [ 0  1  0  0  4  0  0  0  0  2  0  0  5  0  0  0  0  0  0  0  0  2]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  5  0  0  0 10]\n",
            " [ 0  0  0  1  1  0  0  0  2  0  0  0  0  0  0  0  1  4  0  0  0  2]\n",
            " [ 0  1  0  0 15  0  0  0 17  0  0  0 27  0  0  0 32 17  0  0  0 23]\n",
            " [ 0  1  0  0  7  0  0  0  1  0  0  0  3  0  0  0  3  2  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  1 11  0  0  0  3]\n",
            " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  1  0  0  3  6  0  0  0  0]\n",
            " [ 0  0  0  0 31  0  0  0 12  0  0  0 21  0  0  0 66 14  0  0  0  8]\n",
            " [ 0  0  0  0  0  0  0  0 28  0  0  0 12  0  0  0 13 88  0  0  0 22]\n",
            " [ 0  0  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0  1  0  0  0 12]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0 11]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0 10]\n",
            " [ 0  0  0  0  0  0  0  0 13  0  0  0  5  0  0  0  0 36  0  0  0 74]]\n",
            "\n",
            "Overall Metrics for /content/features.csv:\n",
            "Overall Precision = 0.3589\n",
            "Overall Recall = 0.4037\n",
            "Overall F1 Score = 0.3655\n",
            "Overall Accuracy = 0.4037\n",
            "Overall Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1]\n",
            " [  0  27   0   3  34   0   0   0   0   2   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   6   2  13   0   0   6   1   1   0   0   4   0   0   0  12  21\n",
            "    0   0   0   0]\n",
            " [  0   1   3   1  32   0   0   2   1   1   0   0   4   1   0   0  13   6\n",
            "    0   0   0   1]\n",
            " [  0   6   0   1 495   0   0   0  36   2   0   0  29   0   0   0 126  18\n",
            "    0   0   0   4]\n",
            " [  0   2   0   0  11   2   1   3  10   0   0   0   9   1   0   0  11   8\n",
            "    0   0   0   8]\n",
            " [  0   0   1   0   0   0   3   1   6   0   0   0   4   0   0   0   0  21\n",
            "    0   3   0  27]\n",
            " [  0   0   6   0   8   3   1   0   9   0   0   0   6   1   0   0  10  16\n",
            "    0   0   0   6]\n",
            " [  0   0   0   0  70   0   2   0 269   0   0   0  40   0   0   0  62 142\n",
            "    0   0   0 132]\n",
            " [  0   6   0   1  21   0   0   0   0   5   0   0  19   0   0   0   8   3\n",
            "    0   0   0   3]\n",
            " [  0   0   0   0   1   0   2   0   2   0   0   0   6   0   0   0   0  21\n",
            "    0   0   0  34]\n",
            " [  0   0   1   2   4   0   0   1   3   0   0   0   7   0   0   0   6  15\n",
            "    0   1   0  26]\n",
            " [  0   1   2   1  86   0   0   1  60   3   0   0 179   0   0   0 124 116\n",
            "    0   0   0 143]\n",
            " [  0   3   2   0  24   0   0   1   2   2   0   0   8   1   0   0  13   8\n",
            "    0   0   0   2]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   8   1   0   0   5  42\n",
            "    0   0   0   9]\n",
            " [  0   0   0   0   8   0   0   0   6   0   0   0   5   1   0   0  17  27\n",
            "    0   0   0   2]\n",
            " [  0   0   1   0 129   0   0   0  72   0   0   0  73   0   0   0 312 104\n",
            "    0   0   0  25]\n",
            " [  0   0   1   0   6   0   0   0 116   0   0   0  55   0   0   0  71 428\n",
            "    0   0   0 104]\n",
            " [  0   0   0   0   0   0   1   1   5   1   0   0   4   0   0   0   0  10\n",
            "    0   0   0  44]\n",
            " [  0   0   0   0   0   0   1   0   1   0   0   0   1   0   0   0   0   5\n",
            "    0   5   0  53]\n",
            " [  0   0   0   0   1   0   2   0   2   0   0   0   1   0   0   0   0   7\n",
            "    0   1   0  52]\n",
            " [  0   0   0   0   3   0   1   0  70   0   0   0  44   0   0   0  15 154\n",
            "    0   0   0 428]]\n",
            "\n",
            "Fold 1 Metrics for /content/final_features_(1).csv:\n",
            "Precision = 0.4886\n",
            "Recall = 0.4935\n",
            "F1 Score = 0.4875\n",
            "Confusion Matrix:\n",
            "[[150  15  14  32   7   2]\n",
            " [ 23  91  13  21   9  50]\n",
            " [ 25  18  62  23  18  44]\n",
            " [ 31  24  26  88  26   7]\n",
            " [  2  42  20  23  78  37]\n",
            " [  2  28  10   5  30 142]]\n",
            "\n",
            "Fold 2 Metrics for /content/final_features_(1).csv:\n",
            "Precision = 0.4919\n",
            "Recall = 0.4952\n",
            "F1 Score = 0.4883\n",
            "Confusion Matrix:\n",
            "[[150  14  10  42   7   1]\n",
            " [ 22  78  17  16  28  39]\n",
            " [ 30  16  67  33  20  49]\n",
            " [ 34  23  17  86  44  10]\n",
            " [  0  26  13  24  85  21]\n",
            " [  0  21  17   4  27 147]]\n",
            "\n",
            "Fold 3 Metrics for /content/final_features_(1).csv:\n",
            "Precision = 0.5001\n",
            "Recall = 0.5004\n",
            "F1 Score = 0.4898\n",
            "Confusion Matrix:\n",
            "[[136  10   7  28   7   0]\n",
            " [ 31  79   8  28  30  43]\n",
            " [ 23  17  60  28  34  59]\n",
            " [ 27  21  17 109  25   7]\n",
            " [  2  30  16  15  96  25]\n",
            " [  1  25   7   7  40 139]]\n",
            "\n",
            "Fold 4 Metrics for /content/final_features_(1).csv:\n",
            "Precision = 0.4493\n",
            "Recall = 0.4559\n",
            "F1 Score = 0.4438\n",
            "Confusion Matrix:\n",
            "[[133  13  13  40   7   2]\n",
            " [ 22  77  14  26  33  54]\n",
            " [ 32  22  50  43  37  51]\n",
            " [ 36  19  23  91  26  10]\n",
            " [  2  25  15  14  82  22]\n",
            " [  1  15  21   1  34 131]]\n",
            "\n",
            "Fold 5 Metrics for /content/final_features_(1).csv:\n",
            "Precision = 0.4666\n",
            "Recall = 0.4770\n",
            "F1 Score = 0.4674\n",
            "Confusion Matrix:\n",
            "[[140  18  11  39   8   1]\n",
            " [ 21  82  13  29  20  40]\n",
            " [ 27  18  44  40  23  44]\n",
            " [ 49  17  29 102  24   9]\n",
            " [  0  35  13  17  92  31]\n",
            " [  1  19  11   2  38 130]]\n",
            "\n",
            "Overall Metrics for /content/final_features_(1).csv:\n",
            "Overall Precision = 0.4780\n",
            "Overall Recall = 0.4844\n",
            "Overall F1 Score = 0.4758\n",
            "Overall Accuracy = 0.4844\n",
            "Overall Confusion Matrix:\n",
            "[[709  70  55 181  36   6]\n",
            " [119 407  65 120 120 226]\n",
            " [137  91 283 167 132 247]\n",
            " [177 104 112 476 145  43]\n",
            " [  6 158  77  93 433 136]\n",
            " [  5 108  66  19 169 689]]\n",
            "\n",
            "Fold 1 Metrics for /content/final_features_1.csv:\n",
            "Precision = 0.4862\n",
            "Recall = 0.4903\n",
            "F1 Score = 0.4846\n",
            "Confusion Matrix:\n",
            "[[148  15  14  34   7   2]\n",
            " [ 27  91   8  19  12  50]\n",
            " [ 22  20  60  22  17  49]\n",
            " [ 30  19  28  92  25   8]\n",
            " [  2  39  19  24  78  40]\n",
            " [  2  27  13   6  31 138]]\n",
            "\n",
            "Fold 2 Metrics for /content/final_features_1.csv:\n",
            "Precision = 0.4814\n",
            "Recall = 0.4871\n",
            "F1 Score = 0.4782\n",
            "Confusion Matrix:\n",
            "[[151  13  10  42   6   2]\n",
            " [ 21  77  18  14  31  39]\n",
            " [ 29  16  59  35  22  54]\n",
            " [ 35  24  17  84  42  12]\n",
            " [  1  25  15  24  83  21]\n",
            " [  0  20  16   3  28 149]]\n",
            "\n",
            "Fold 3 Metrics for /content/final_features_1.csv:\n",
            "Precision = 0.4937\n",
            "Recall = 0.4947\n",
            "F1 Score = 0.4839\n",
            "Confusion Matrix:\n",
            "[[136  10   7  27   8   0]\n",
            " [ 30  79  10  27  29  44]\n",
            " [ 22  18  59  29  31  62]\n",
            " [ 29  21  18 106  24   8]\n",
            " [  2  31  15  17  91  28]\n",
            " [  1  25   6   7  39 141]]\n",
            "\n",
            "Fold 4 Metrics for /content/final_features_1.csv:\n",
            "Precision = 0.4363\n",
            "Recall = 0.4446\n",
            "F1 Score = 0.4316\n",
            "Confusion Matrix:\n",
            "[[131  18  12  39   6   2]\n",
            " [ 22  79  14  24  34  53]\n",
            " [ 32  24  45  43  36  55]\n",
            " [ 36  22  22  85  28  12]\n",
            " [  2  26  13  17  78  24]\n",
            " [  1  13  22   3  32 132]]\n",
            "\n",
            "Fold 5 Metrics for /content/final_features_1.csv:\n",
            "Precision = 0.4549\n",
            "Recall = 0.4648\n",
            "F1 Score = 0.4552\n",
            "Confusion Matrix:\n",
            "[[138  18  11  41   8   1]\n",
            " [ 21  80  10  29  25  40]\n",
            " [ 25  21  41  35  26  48]\n",
            " [ 48  19  30  99  24  10]\n",
            " [  0  34  13  18  91  32]\n",
            " [  1  21  12   2  39 126]]\n",
            "\n",
            "Overall Metrics for /content/final_features_1.csv:\n",
            "Overall Precision = 0.4696\n",
            "Overall Recall = 0.4763\n",
            "Overall F1 Score = 0.4671\n",
            "Overall Accuracy = 0.4763\n",
            "Overall Confusion Matrix:\n",
            "[[704  74  54 183  35   7]\n",
            " [121 406  60 113 131 226]\n",
            " [130  99 264 164 132 268]\n",
            " [178 105 115 466 143  50]\n",
            " [  7 155  75 100 421 145]\n",
            " [  5 106  69  21 169 686]]\n"
          ]
        }
      ]
    }
  ]
}